import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from textblob import TextBlob

# Load dataset into a DataFrame with a different encoding
df = pd.read_csv('sentiment.csv', encoding='ISO-8859-1')


# Convert all reviews to strings (if they are not already)
df['Review'] = df['Review'].astype(str)

# Define a function to determine sentiment based on polarity using TextBlob
def get_sentiment(review):
    # Ensure that the review is a valid string
    if not isinstance(review, str) or review.strip() == '':
        return 0 # Neutral for empty or invalid reviews
    analysis = TextBlob(review)
    # Classify the sentiment based on polarity value
    if analysis.sentiment.polarity > 0.2:
        return 1 # Positive
    elif analysis.sentiment.polarity < -0.2:
        return -1 # Negative
    else:
        return 0 # Neutral

# Apply sentiment analysis to the reviews
df['Sentiment'] = df['Review'].apply(get_sentiment)


# Remove rows with missing values
df = df.dropna()

# Data preprocessing
X = df['Review']
y = df['Sentiment']

# Feature extraction using TF-IDF Vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=1000)
X = vectorizer.fit_transform(X).toarray()

# Split the dataset into training and testing sets (with stratified sampling)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# SVM model training
from sklearn.svm import SVC
model = SVC(kernel='linear')
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Performance metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro', zero_division=0)
recall = recall_score(y_test, y_pred, average='macro', zero_division=0)

print(f"\nAccuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")



# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Neutral', 'Positive'], yticklabels=['Negative', 'Neutral', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Sentiment distribution
sentiment_counts = df['Sentiment'].value_counts()
ax = sentiment_counts.plot(kind='bar', color=['red', 'gray', 'green'])
#sentiment_counts.plot(kind='bar', color=['red', 'gray', 'green'])
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Number of Reviews')
ax.set_xticklabels(['Negative', 'Neutral', 'Positive'], rotation=0, ha='center')
#plt.xticks(ticks=[-1, 0, 1], labels=['Negative', 'Neutral', 'Positive'], rotation=0, ha='center')
plt.show()

# Suggested products based on positive reviews from the dataset
positive_reviews = df[df['Sentiment'] == 1]['ProductName']
neutral_reviews = df[df['Sentiment'] == 0]['ProductName']

print("\nTop Recommended Products based on Positive Reviews:")
for product in positive_reviews:
    print(product)

print("\nNeutral Reviewed Products:")
for product in neutral_reviews:
    print(product)
